// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --version 2
// REQUIRES: amdgpu-registered-target
// RUN: %clang_cc1 -O0 -debug-info-kind=limited -gheterogeneous-dwarf -triple amdgcn-amd-amdhsa -x hip -emit-llvm -fcuda-is-device -o - %s | FileCheck %s

// Notes:
// * There is no test involving transparent_union, as this isn't supported in
// C++, and so is not supported in HIP.
// * There is no test involving flexible array members, as this isn't supported
// in C++ without an extension.
// * AMDGCN uses the ItaniumCXXABI, which seems to require one trivial,
// non-deleted copy or move constructor in order to allow Default passing,
// otherwise it selects Indirect. There is a "non-ByVal" form of Indirect,
// which seems to add an extra indirection to avoid a copy, but this is only
// used by the MicrosoftCXXABI, so AFAICT it is impossible to construct for
// AMDGCN.
// * The tests are not exhaustive by any stretch, but try to cover all of the
// relevant corner cases from the perspective of debug info. One notable
// omission is any consideration for return values, as this isn't (currently)
// present in the debug info at all.

#define __device__ __attribute__((device))
#define __global__ __attribute__((global))
#define int8_t char
#define uint8_t unsigned int8_t
#define int16_t short
#define uint16_t unsigned int16_t
#define int32_t int
#define uint32_t unsigned int32_t
#define int64_t long
#define uint64_t unsigned int64_t

struct StructEmpty {};
struct StructSingleElement {
  int8_t Element0;
};
struct StructSingleElementRecursive {
  StructSingleElement Element0;
};
struct StructTrivialCopyTrivialMove {
  int8_t Element0;
  __device__ StructTrivialCopyTrivialMove(const StructTrivialCopyTrivialMove &) = default;
  __device__ StructTrivialCopyTrivialMove(StructTrivialCopyTrivialMove &&) = default;
};
struct StructNoCopyTrivialMove {
  int8_t Element0;
  __device__ StructNoCopyTrivialMove(const StructNoCopyTrivialMove &) = delete;
  __device__ StructNoCopyTrivialMove(StructNoCopyTrivialMove &&) = default;
};
struct StructTrivialCopyNoMove {
  int8_t Element0;
  __device__ StructTrivialCopyNoMove(const StructTrivialCopyNoMove &) = default;
  __device__ StructTrivialCopyNoMove(StructTrivialCopyNoMove &&) = delete;
};
struct StructNoCopyNoMove {
  int8_t Element0;
  __device__ StructNoCopyNoMove(const StructNoCopyNoMove &) = delete;
  __device__ StructNoCopyNoMove(StructNoCopyNoMove &&) = delete;
};
template <unsigned N>
struct StructNBytes {
  static_assert(N > 1, "");
  int8_t Element0;
  int8_t Elements[N - 1u];
};
enum EnumInt8T : int8_t {};
enum EnumUInt8T : uint8_t {};
enum EnumInt16T : int16_t {};
enum EnumUInt16T : uint16_t {};
enum EnumInt32T : int32_t {};
enum EnumUInt32T : uint32_t {};
enum EnumInt64T : int64_t {};
enum EnumUInt64T : uint64_t {};
struct StructSinglePointerElement {
  int32_t *Element0;
};
struct StructPointerElements {
  int32_t *Element0;
  float *Element1;
};
struct StructMultipleElements {
  int32_t Element0;
  int64_t Element1;
};

// CHECK-LABEL: define dso_local void @_Z21Test_Func_StructEmpty11StructEmpty
// CHECK-SAME: () #[[ATTR0:[0-9]+]] !dbg [[DBG27:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP:%.*]] = alloca [[STRUCT_STRUCTEMPTY:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP0:%.*]] = addrspacecast ptr addrspace(5) [[TMP]] to ptr
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META33:![0-9]+]], metadata ptr addrspace(5) [[TMP]]), !dbg [[DBG34:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG35:![0-9]+]]
//
__device__ void Test_Func_StructEmpty(StructEmpty) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z21Test_Kern_StructEmpty11StructEmpty
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTEMPTY:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2:[0-9]+]] !dbg [[DBG36:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTEMPTY]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 1, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META39:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG40:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG41:![0-9]+]]
//
__global__ void Test_Kern_StructEmpty(StructEmpty) {}
// CHECK-LABEL: define dso_local void @_Z29Test_Func_StructSingleElement19StructSingleElement
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG42:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTSINGLEELEMENT:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTSINGLEELEMENT]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META50:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG51:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG52:![0-9]+]]
//
__device__ void Test_Func_StructSingleElement(StructSingleElement) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z29Test_Kern_StructSingleElement19StructSingleElement
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG53:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTSINGLEELEMENT:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTSINGLEELEMENT]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META56:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG57:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG58:![0-9]+]]
//
__global__ void Test_Kern_StructSingleElement(StructSingleElement) {}
// CHECK-LABEL: define dso_local void @_Z38Test_Func_StructSingleElementRecursive28StructSingleElementRecursive
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG59:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTSINGLEELEMENTRECURSIVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTSINGLEELEMENTRECURSIVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    [[COERCE_DIVE1:%.*]] = getelementptr inbounds [[STRUCT_STRUCTSINGLEELEMENT:%.*]], ptr [[COERCE_DIVE]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE1]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META67:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG68:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG69:![0-9]+]]
//
__device__ void Test_Func_StructSingleElementRecursive(StructSingleElementRecursive) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z38Test_Kern_StructSingleElementRecursive28StructSingleElementRecursive
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG70:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTSINGLEELEMENTRECURSIVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTSINGLEELEMENTRECURSIVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    [[COERCE_DIVE1:%.*]] = getelementptr inbounds [[STRUCT_STRUCTSINGLEELEMENT:%.*]], ptr [[COERCE_DIVE]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE1]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META73:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG74:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG75:![0-9]+]]
//
__global__ void Test_Kern_StructSingleElementRecursive(StructSingleElementRecursive) {}
// CHECK-LABEL: define dso_local void @_Z38Test_Func_StructTrivialCopyTrivialMove28StructTrivialCopyTrivialMove
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG76:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTTRIVIALCOPYTRIVIALMOVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTTRIVIALCOPYTRIVIALMOVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META94:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG95:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG96:![0-9]+]]
//
__device__ void Test_Func_StructTrivialCopyTrivialMove(StructTrivialCopyTrivialMove) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z38Test_Kern_StructTrivialCopyTrivialMove28StructTrivialCopyTrivialMove
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG97:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTTRIVIALCOPYTRIVIALMOVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTTRIVIALCOPYTRIVIALMOVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META100:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG101:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG102:![0-9]+]]
//
__global__ void Test_Kern_StructTrivialCopyTrivialMove(StructTrivialCopyTrivialMove) {}
// CHECK-LABEL: define dso_local void @_Z33Test_Func_StructNoCopyTrivialMove23StructNoCopyTrivialMove
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG103:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNOCOPYTRIVIALMOVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTNOCOPYTRIVIALMOVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META121:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG122:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG123:![0-9]+]]
//
__device__ void Test_Func_StructNoCopyTrivialMove(StructNoCopyTrivialMove) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z33Test_Kern_StructNoCopyTrivialMove23StructNoCopyTrivialMove
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG124:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNOCOPYTRIVIALMOVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTNOCOPYTRIVIALMOVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META127:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG128:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG129:![0-9]+]]
//
__global__ void Test_Kern_StructNoCopyTrivialMove(StructNoCopyTrivialMove) {}
// CHECK-LABEL: define dso_local void @_Z33Test_Func_StructTrivialCopyNoMove23StructTrivialCopyNoMove
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG130:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTTRIVIALCOPYNOMOVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTTRIVIALCOPYNOMOVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META148:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG149:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG150:![0-9]+]]
//
__device__ void Test_Func_StructTrivialCopyNoMove(StructTrivialCopyNoMove) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z33Test_Kern_StructTrivialCopyNoMove23StructTrivialCopyNoMove
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG151:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTTRIVIALCOPYNOMOVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTTRIVIALCOPYNOMOVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META154:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG155:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG156:![0-9]+]]
//
__global__ void Test_Kern_StructTrivialCopyNoMove(StructTrivialCopyNoMove) {}
// CHECK-LABEL: define dso_local void @_Z28Test_Func_StructNoCopyNoMove18StructNoCopyNoMove
// CHECK-SAME: (ptr addrspace(5) [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG157:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTINDIRECT_ADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTINDIRECT_ADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTINDIRECT_ADDR]] to ptr
// CHECK-NEXT:    store ptr addrspace(5) [[TMP0]], ptr [[DOTINDIRECT_ADDR_ASCAST]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META175:![0-9]+]], metadata ptr addrspace(5) [[DOTINDIRECT_ADDR]]), !dbg [[DBG176:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG177:![0-9]+]]
//
__device__ void Test_Func_StructNoCopyNoMove(StructNoCopyNoMove) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z28Test_Kern_StructNoCopyNoMove18StructNoCopyNoMove
// CHECK-SAME: (i8 [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG178:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNOCOPYNOMOVE:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTNOCOPYNOMOVE]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META181:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG182:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG183:![0-9]+]]
//
__global__ void Test_Kern_StructNoCopyNoMove(StructNoCopyNoMove) {}
// CHECK-LABEL: define dso_local void @_Z22Test_Func_Struct2Bytes12StructNBytesILj2EE
// CHECK-SAME: (i16 [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG184:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNBYTES:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    store i16 [[DOTCOERCE]], ptr [[TMP1]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META198:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG199:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG200:![0-9]+]]
//
__device__ void Test_Func_Struct2Bytes(StructNBytes<2>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z22Test_Kern_Struct2Bytes12StructNBytesILj2EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG201:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 2, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META204:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG205:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG206:![0-9]+]]
//
__global__ void Test_Kern_Struct2Bytes(StructNBytes<2>) {}
// FIXME: I'm unsure why there is a second alloca, and both a store and a memcpy,
// but I assume it relates to padding; ; it should have the same result as e.g.
// the code from Test_Func_Struct2Bytes
// CHECK-LABEL: define dso_local void @_Z22Test_Func_Struct3Bytes12StructNBytesILj3EE
// CHECK-SAME: (i32 [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG207:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNBYTES_0:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP_COERCE:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[TMP_COERCE_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[TMP_COERCE]] to ptr
// CHECK-NEXT:    store i32 [[DOTCOERCE]], ptr [[TMP_COERCE_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 1 [[TMP1]], ptr align 4 [[TMP_COERCE_ASCAST]], i64 3, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META221:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG222:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG223:![0-9]+]]
//
__device__ void Test_Func_Struct3Bytes(StructNBytes<3>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z22Test_Kern_Struct3Bytes12StructNBytesILj3EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES_0:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG224:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES_0]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 3, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META227:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG228:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG229:![0-9]+]]
//
__global__ void Test_Kern_Struct3Bytes(StructNBytes<3>) {}
// CHECK-LABEL: define dso_local void @_Z22Test_Func_Struct4Bytes12StructNBytesILj4EE
// CHECK-SAME: (i32 [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG230:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNBYTES_1:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    store i32 [[DOTCOERCE]], ptr [[TMP1]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META244:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG245:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG246:![0-9]+]]
//
__device__ void Test_Func_Struct4Bytes(StructNBytes<4>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z22Test_Kern_Struct4Bytes12StructNBytesILj4EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES_1:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG247:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES_1]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 4, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META250:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG251:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG252:![0-9]+]]
//
__global__ void Test_Kern_Struct4Bytes(StructNBytes<4>) {}
// CHECK-LABEL: define dso_local void @_Z22Test_Func_Struct5Bytes12StructNBytesILj5EE
// CHECK-SAME: ([2 x i32] [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG253:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNBYTES_2:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP_COERCE:%.*]] = alloca [2 x i32], align 4, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[TMP_COERCE_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[TMP_COERCE]] to ptr
// CHECK-NEXT:    store [2 x i32] [[DOTCOERCE]], ptr [[TMP_COERCE_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 1 [[TMP1]], ptr align 4 [[TMP_COERCE_ASCAST]], i64 5, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META267:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG268:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG269:![0-9]+]]
//
__device__ void Test_Func_Struct5Bytes(StructNBytes<5>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z22Test_Kern_Struct5Bytes12StructNBytesILj5EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES_2:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG270:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES_2]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 5, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META273:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG274:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG275:![0-9]+]]
//
__global__ void Test_Kern_Struct5Bytes(StructNBytes<5>) {}
// CHECK-LABEL: define dso_local void @_Z22Test_Func_Struct6Bytes12StructNBytesILj6EE
// CHECK-SAME: ([2 x i32] [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG276:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNBYTES_3:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP_COERCE:%.*]] = alloca [2 x i32], align 4, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[TMP_COERCE_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[TMP_COERCE]] to ptr
// CHECK-NEXT:    store [2 x i32] [[DOTCOERCE]], ptr [[TMP_COERCE_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 1 [[TMP1]], ptr align 4 [[TMP_COERCE_ASCAST]], i64 6, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META290:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG291:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG292:![0-9]+]]
//
__device__ void Test_Func_Struct6Bytes(StructNBytes<6>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z22Test_Kern_Struct6Bytes12StructNBytesILj6EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES_3:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG293:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES_3]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 6, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META296:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG297:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG298:![0-9]+]]
//
__global__ void Test_Kern_Struct6Bytes(StructNBytes<6>) {}
// CHECK-LABEL: define dso_local void @_Z22Test_Func_Struct7Bytes12StructNBytesILj7EE
// CHECK-SAME: ([2 x i32] [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG299:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNBYTES_4:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP_COERCE:%.*]] = alloca [2 x i32], align 4, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[TMP_COERCE_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[TMP_COERCE]] to ptr
// CHECK-NEXT:    store [2 x i32] [[DOTCOERCE]], ptr [[TMP_COERCE_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 1 [[TMP1]], ptr align 4 [[TMP_COERCE_ASCAST]], i64 7, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META313:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG314:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG315:![0-9]+]]
//
__device__ void Test_Func_Struct7Bytes(StructNBytes<7>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z22Test_Kern_Struct7Bytes12StructNBytesILj7EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES_4:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG316:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES_4]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 7, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META319:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG320:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG321:![0-9]+]]
//
__global__ void Test_Kern_Struct7Bytes(StructNBytes<7>) {}
// CHECK-LABEL: define dso_local void @_Z22Test_Func_Struct8Bytes12StructNBytesILj8EE
// CHECK-SAME: ([2 x i32] [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG322:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNBYTES_5:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    store [2 x i32] [[DOTCOERCE]], ptr [[TMP1]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META336:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG337:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG338:![0-9]+]]
//
__device__ void Test_Func_Struct8Bytes(StructNBytes<8>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z22Test_Kern_Struct8Bytes12StructNBytesILj8EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES_5:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG339:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES_5]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 8, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META342:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG343:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG344:![0-9]+]]
//
__global__ void Test_Kern_Struct8Bytes(StructNBytes<8>) {}
// CHECK-LABEL: define dso_local void @_Z22Test_Func_Struct9Bytes12StructNBytesILj9EE
// CHECK-SAME: (i8 [[DOTCOERCE0:%.*]], [8 x i8] [[DOTCOERCE1:%.*]]) #[[ATTR0]] !dbg [[DBG345:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTNBYTES_6:%.*]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT_STRUCTNBYTES_6]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i8 [[DOTCOERCE0]], ptr [[TMP2]], align 1
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT_STRUCTNBYTES_6]], ptr [[TMP1]], i32 0, i32 1
// CHECK-NEXT:    store [8 x i8] [[DOTCOERCE1]], ptr [[TMP3]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META359:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG360:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG361:![0-9]+]]
//
__device__ void Test_Func_Struct9Bytes(StructNBytes<9>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z22Test_Kern_Struct9Bytes12StructNBytesILj9EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES_6:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG362:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES_6]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 9, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META365:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG366:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG367:![0-9]+]]
//
__global__ void Test_Kern_Struct9Bytes(StructNBytes<9>) {}
// DAVE-CHECK: define dso_local void @_Z23Test_Func_Struct64Bytes12StructNBytesILj64EE(ptr addrspace(5)byval(%struct.StructNBytes.7) align 1 %0)
// DAVE-CHECK-NOT: alloca
// DAVE-CHECK: call void @llvm.dbg.def(metadata !{{[0-9]+}}, metadata ptr addrspace(5) %0),
// CHECK-LABEL: define dso_local void @_Z23Test_Func_Struct64Bytes12StructNBytesILj64EE
// CHECK-SAME: (ptr addrspace(5) byval([[STRUCT_STRUCTNBYTES_7:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG368:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META382:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG383:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG384:![0-9]+]]
//
__device__ void Test_Func_Struct64Bytes(StructNBytes<64>) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z23Test_Kern_Struct64Bytes12StructNBytesILj64EE
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTNBYTES_7:%.*]]) align 1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG385:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTNBYTES_7]], align 1, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 1 [[TMP1]], ptr addrspace(4) align 1 [[TMP0]], i64 64, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META388:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG389:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG390:![0-9]+]]
//
__global__ void Test_Kern_Struct64Bytes(StructNBytes<64>) {}
// CHECK-LABEL: define dso_local void @_Z15Test_Func_Int8Tc
// CHECK-SAME: (i8 signext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG391:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i8 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META396:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG397:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG398:![0-9]+]]
//
__device__ void Test_Func_Int8T(int8_t) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z15Test_Kern_Int8Tc
// CHECK-SAME: (i8 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG399:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i8 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META402:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG403:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG404:![0-9]+]]
//
__global__ void Test_Kern_Int8T(int8_t) {}
// CHECK-LABEL: define dso_local void @_Z16Test_Func_UInt8Th
// CHECK-SAME: (i8 zeroext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG405:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i8 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META410:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG411:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG412:![0-9]+]]
//
__device__ void Test_Func_UInt8T(uint8_t) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z16Test_Kern_UInt8Th
// CHECK-SAME: (i8 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG413:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i8 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META416:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG417:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG418:![0-9]+]]
//
__global__ void Test_Kern_UInt8T(uint8_t) {}
// CHECK-LABEL: define dso_local void @_Z16Test_Func_Int16Ts
// CHECK-SAME: (i16 signext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG419:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i16, align 2, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i16 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 2
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META424:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG425:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG426:![0-9]+]]
//
__device__ void Test_Func_Int16T(int16_t) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z16Test_Kern_Int16Ts
// CHECK-SAME: (i16 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG427:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i16, align 2, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i16 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 2
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META430:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG431:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG432:![0-9]+]]
//
__global__ void Test_Kern_Int16T(int16_t) {}
// CHECK-LABEL: define dso_local void @_Z17Test_Func_UInt16Tt
// CHECK-SAME: (i16 zeroext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG433:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i16, align 2, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i16 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 2
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META438:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG439:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG440:![0-9]+]]
//
__device__ void Test_Func_UInt16T(uint16_t) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z17Test_Kern_UInt16Tt
// CHECK-SAME: (i16 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG441:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i16, align 2, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i16 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 2
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META444:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG445:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG446:![0-9]+]]
//
__global__ void Test_Kern_UInt16T(uint16_t) {}
// CHECK-LABEL: define dso_local void @_Z16Test_Func_Int32Ti
// CHECK-SAME: (i32 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG447:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META452:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG453:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG454:![0-9]+]]
//
__device__ void Test_Func_Int32T(int32_t) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z16Test_Kern_Int32Ti
// CHECK-SAME: (i32 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG455:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META458:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG459:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG460:![0-9]+]]
//
__global__ void Test_Kern_Int32T(int32_t) {}
// CHECK-LABEL: define dso_local void @_Z17Test_Func_UInt32Tj
// CHECK-SAME: (i32 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG461:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META466:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG467:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG468:![0-9]+]]
//
__device__ void Test_Func_UInt32T(uint32_t) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z17Test_Kern_UInt32Tj
// CHECK-SAME: (i32 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG469:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META472:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG473:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG474:![0-9]+]]
//
__global__ void Test_Kern_UInt32T(uint32_t) {}
// CHECK-LABEL: define dso_local void @_Z16Test_Func_Int64Tl
// CHECK-SAME: (i64 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG475:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META480:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG481:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG482:![0-9]+]]
//
__device__ void Test_Func_Int64T(int64_t) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z16Test_Kern_Int64Tl
// CHECK-SAME: (i64 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG483:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META486:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG487:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG488:![0-9]+]]
//
__global__ void Test_Kern_Int64T(int64_t) {}
// CHECK-LABEL: define dso_local void @_Z17Test_Func_UInt64Tm
// CHECK-SAME: (i64 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG489:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META494:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG495:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG496:![0-9]+]]
//
__device__ void Test_Func_UInt64T(uint64_t) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z17Test_Kern_UInt64Tm
// CHECK-SAME: (i64 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG497:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META500:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG501:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG502:![0-9]+]]
//
__global__ void Test_Kern_UInt64T(uint64_t) {}
// CHECK-LABEL: define dso_local void @_Z19Test_Func_EnumInt8T9EnumInt8T
// CHECK-SAME: (i8 signext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG503:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i8 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META508:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG509:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG510:![0-9]+]]
//
__device__ void Test_Func_EnumInt8T(EnumInt8T) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z19Test_Kern_EnumInt8T9EnumInt8T
// CHECK-SAME: (i8 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG511:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i8 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META514:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG515:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG516:![0-9]+]]
//
__global__ void Test_Kern_EnumInt8T(EnumInt8T) {}
// CHECK-LABEL: define dso_local void @_Z20Test_Func_EnumUInt8T10EnumUInt8T
// CHECK-SAME: (i8 zeroext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG517:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i8 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META522:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG523:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG524:![0-9]+]]
//
__device__ void Test_Func_EnumUInt8T(EnumUInt8T) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z20Test_Kern_EnumUInt8T10EnumUInt8T
// CHECK-SAME: (i8 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG525:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i8 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META528:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG529:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG530:![0-9]+]]
//
__global__ void Test_Kern_EnumUInt8T(EnumUInt8T) {}
// CHECK-LABEL: define dso_local void @_Z20Test_Func_EnumInt16T10EnumInt16T
// CHECK-SAME: (i16 signext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG531:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i16, align 2, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i16 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 2
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META536:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG537:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG538:![0-9]+]]
//
__device__ void Test_Func_EnumInt16T(EnumInt16T) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z20Test_Kern_EnumInt16T10EnumInt16T
// CHECK-SAME: (i16 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG539:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i16, align 2, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i16 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 2
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META542:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG543:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG544:![0-9]+]]
//
__global__ void Test_Kern_EnumInt16T(EnumInt16T) {}
// CHECK-LABEL: define dso_local void @_Z21Test_Func_EnumUInt16T11EnumUInt16T
// CHECK-SAME: (i16 zeroext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG545:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i16, align 2, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i16 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 2
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META550:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG551:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG552:![0-9]+]]
//
__device__ void Test_Func_EnumUInt16T(EnumUInt16T) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z21Test_Kern_EnumUInt16T11EnumUInt16T
// CHECK-SAME: (i16 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG553:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i16, align 2, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i16 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 2
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META556:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG557:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG558:![0-9]+]]
//
__global__ void Test_Kern_EnumUInt16T(EnumUInt16T) {}
// CHECK-LABEL: define dso_local void @_Z20Test_Func_EnumInt32T10EnumInt32T
// CHECK-SAME: (i32 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG559:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META564:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG565:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG566:![0-9]+]]
//
__device__ void Test_Func_EnumInt32T(EnumInt32T) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z20Test_Kern_EnumInt32T10EnumInt32T
// CHECK-SAME: (i32 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG567:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META570:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG571:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG572:![0-9]+]]
//
__global__ void Test_Kern_EnumInt32T(EnumInt32T) {}
// CHECK-LABEL: define dso_local void @_Z21Test_Func_EnumUInt32T11EnumUInt32T
// CHECK-SAME: (i32 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG573:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META578:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG579:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG580:![0-9]+]]
//
__device__ void Test_Func_EnumUInt32T(EnumUInt32T) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z21Test_Kern_EnumUInt32T11EnumUInt32T
// CHECK-SAME: (i32 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG581:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META584:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG585:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG586:![0-9]+]]
//
__global__ void Test_Kern_EnumUInt32T(EnumUInt32T) {}
// CHECK-LABEL: define dso_local void @_Z20Test_Func_EnumInt64T10EnumInt64T
// CHECK-SAME: (i64 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG587:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META592:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG593:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG594:![0-9]+]]
//
__device__ void Test_Func_EnumInt64T(EnumInt64T) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z20Test_Kern_EnumInt64T10EnumInt64T
// CHECK-SAME: (i64 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG595:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META598:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG599:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG600:![0-9]+]]
//
__global__ void Test_Kern_EnumInt64T(EnumInt64T) {}
// CHECK-LABEL: define dso_local void @_Z21Test_Func_EnumUInt64T11EnumUInt64T
// CHECK-SAME: (i64 [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG601:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META606:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG607:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG608:![0-9]+]]
//
__device__ void Test_Func_EnumUInt64T(EnumUInt64T) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z21Test_Kern_EnumUInt64T11EnumUInt64T
// CHECK-SAME: (i64 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG609:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META612:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG613:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG614:![0-9]+]]
//
__global__ void Test_Kern_EnumUInt64T(EnumUInt64T) {}
// CHECK-LABEL: define dso_local void @_Z27Test_Func_PromotableIntegerb
// CHECK-SAME: (i1 zeroext [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG615:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP0]] to i8
// CHECK-NEXT:    store i8 [[FROMBOOL]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META621:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG622:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG623:![0-9]+]]
//
__device__ void Test_Func_PromotableInteger(bool) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z27Test_Kern_PromotableIntegerb
// CHECK-SAME: (i1 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG624:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i8, align 1, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    [[FROMBOOL:%.*]] = zext i1 [[TMP0]] to i8
// CHECK-NEXT:    store i8 [[FROMBOOL]], ptr [[DOTADDR_ASCAST]], align 1
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META627:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG628:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG629:![0-9]+]]
//
__global__ void Test_Kern_PromotableInteger(bool) {}
// CHECK-LABEL: define dso_local void @_Z17Test_Func_PointerPi
// CHECK-SAME: (ptr [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG630:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META636:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG637:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG638:![0-9]+]]
//
__device__ void Test_Func_Pointer(int32_t *) {}
// FIXME: There is a store, load, store sequence through another alloca here,
// which I don't understand the intent of
// call void @llvm.dbg.def(metadata !{{[0-9]+}}, metadata ptr addrspace(5) %.addr),
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z17Test_Kern_PointerPi
// CHECK-SAME: (ptr addrspace(1) [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG639:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    [[TMP2:%.*]] = addrspacecast ptr addrspace(1) [[DOTCOERCE]] to ptr
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[TMP1]], align 8
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META642:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG643:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG644:![0-9]+]]
//
__global__ void Test_Kern_Pointer(int32_t *) {}
// CHECK-LABEL: define dso_local void @_Z19Test_Func_ReferenceRi
// CHECK-SAME: (ptr nonnull align 4 dereferenceable(4) [[TMP0:%.*]]) #[[ATTR0]] !dbg [[DBG645:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META651:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG652:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG653:![0-9]+]]
//
__device__ void Test_Func_Reference(int32_t &) {}
// FIXME: There is a store, load, store sequence through another alloca here,
// which I don't understand the intent of
// call void @llvm.dbg.def(metadata !{{[0-9]+}}, metadata ptr addrspace(5) %.addr),
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z19Test_Kern_ReferenceRi
// CHECK-SAME: (ptr addrspace(1) nonnull align 4 dereferenceable(4) [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG654:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    [[TMP2:%.*]] = addrspacecast ptr addrspace(1) [[DOTCOERCE]] to ptr
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[TMP1]], align 8
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META657:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG658:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG659:![0-9]+]]
//
__global__ void Test_Kern_Reference(int32_t &) {}
// CHECK-LABEL: define dso_local void @_Z36Test_Func_StructSinglePointerElement26StructSinglePointerElement
// CHECK-SAME: (ptr [[DOTCOERCE:%.*]]) #[[ATTR0]] !dbg [[DBG660:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTSINGLEPOINTERELEMENT:%.*]], align 8, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTSINGLEPOINTERELEMENT]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[DOTCOERCE]], ptr [[COERCE_DIVE]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META668:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG669:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG670:![0-9]+]]
//
__device__ void Test_Func_StructSinglePointerElement(StructSinglePointerElement) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z36Test_Kern_StructSinglePointerElement26StructSinglePointerElement
// CHECK-SAME: (ptr addrspace(1) [[DOTCOERCE:%.*]]) #[[ATTR2]] !dbg [[DBG671:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTSINGLEPOINTERELEMENT:%.*]], align 8, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[COERCE_DIVE:%.*]] = getelementptr inbounds [[STRUCT_STRUCTSINGLEPOINTERELEMENT]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    [[TMP2:%.*]] = addrspacecast ptr addrspace(1) [[DOTCOERCE]] to ptr
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[COERCE_DIVE]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META674:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG675:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG676:![0-9]+]]
//
__global__ void Test_Kern_StructSinglePointerElement(StructSinglePointerElement) {}
// CHECK-LABEL: define dso_local void @_Z31Test_Func_StructPointerElements21StructPointerElements
// CHECK-SAME: (ptr [[DOTCOERCE0:%.*]], ptr [[DOTCOERCE1:%.*]]) #[[ATTR0]] !dbg [[DBG677:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = alloca [[STRUCT_STRUCTPOINTERELEMENTS:%.*]], align 8, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[TMP0]] to ptr
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT_STRUCTPOINTERELEMENTS]], ptr [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[DOTCOERCE0]], ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[STRUCT_STRUCTPOINTERELEMENTS]], ptr [[TMP1]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[DOTCOERCE1]], ptr [[TMP3]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META688:![0-9]+]], metadata ptr addrspace(5) [[TMP0]]), !dbg [[DBG689:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG690:![0-9]+]]
//
__device__ void Test_Func_StructPointerElements(StructPointerElements) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z31Test_Kern_StructPointerElements21StructPointerElements
// CHECK-SAME: (ptr addrspace(4) byref([[STRUCT_STRUCTPOINTERELEMENTS:%.*]]) align 8 [[TMP0:%.*]]) #[[ATTR2]] !dbg [[DBG691:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTPOINTERELEMENTS]], align 8, addrspace(5)
// CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 8 [[TMP1]], ptr addrspace(4) align 8 [[TMP0]], i64 16, i1 false)
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META694:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG695:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG696:![0-9]+]]
//
__global__ void Test_Kern_StructPointerElements(StructPointerElements) {}
// CHECK-LABEL: define dso_local void @_Z37Test_Func_ParamRegLimitExpandedStructlllllli22StructMultipleElements
// CHECK-SAME: (i64 [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], i64 [[TMP3:%.*]], i64 [[TMP4:%.*]], i64 [[TMP5:%.*]], i32 [[TMP6:%.*]], i32 [[DOTCOERCE0:%.*]], i64 [[DOTCOERCE1:%.*]]) #[[ATTR0]] !dbg [[DBG697:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP7:%.*]] = alloca [[STRUCT_STRUCTMULTIPLEELEMENTS:%.*]], align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR1:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR3:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR4:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR5:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR6:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[TMP8:%.*]] = addrspacecast ptr addrspace(5) [[TMP7]] to ptr
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    [[DOTADDR1_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR1]] to ptr
// CHECK-NEXT:    [[DOTADDR2_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR2]] to ptr
// CHECK-NEXT:    [[DOTADDR3_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR3]] to ptr
// CHECK-NEXT:    [[DOTADDR4_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR4]] to ptr
// CHECK-NEXT:    [[DOTADDR5_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR5]] to ptr
// CHECK-NEXT:    [[DOTADDR6_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR6]] to ptr
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds [[STRUCT_STRUCTMULTIPLEELEMENTS]], ptr [[TMP8]], i32 0, i32 0
// CHECK-NEXT:    store i32 [[DOTCOERCE0]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds [[STRUCT_STRUCTMULTIPLEELEMENTS]], ptr [[TMP8]], i32 0, i32 1
// CHECK-NEXT:    store i64 [[DOTCOERCE1]], ptr [[TMP10]], align 8
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META713:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG714:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP1]], ptr [[DOTADDR1_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META715:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR1]]), !dbg [[DBG716:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META717:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR2]]), !dbg [[DBG718:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP3]], ptr [[DOTADDR3_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META719:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR3]]), !dbg [[DBG720:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP4]], ptr [[DOTADDR4_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META721:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR4]]), !dbg [[DBG722:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP5]], ptr [[DOTADDR5_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META723:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR5]]), !dbg [[DBG724:![0-9]+]]
// CHECK-NEXT:    store i32 [[TMP6]], ptr [[DOTADDR6_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META725:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR6]]), !dbg [[DBG726:![0-9]+]]
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META727:![0-9]+]], metadata ptr addrspace(5) [[TMP7]]), !dbg [[DBG728:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG729:![0-9]+]]
//
__device__ void Test_Func_ParamRegLimitExpandedStruct(int64_t, int64_t, int64_t, int64_t, int64_t, int64_t, int32_t, StructMultipleElements) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z37Test_Kern_ParamRegLimitExpandedStructlllllli22StructMultipleElements
// CHECK-SAME: (i64 [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], i64 [[TMP3:%.*]], i64 [[TMP4:%.*]], i64 [[TMP5:%.*]], i32 [[TMP6:%.*]], ptr addrspace(4) byref([[STRUCT_STRUCTMULTIPLEELEMENTS:%.*]]) align 8 [[TMP7:%.*]]) #[[ATTR2]] !dbg [[DBG730:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTMULTIPLEELEMENTS]], align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR1:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR3:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR4:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR5:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR6:%.*]] = alloca i32, align 4, addrspace(5)
// CHECK-NEXT:    [[TMP8:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    [[DOTADDR1_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR1]] to ptr
// CHECK-NEXT:    [[DOTADDR2_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR2]] to ptr
// CHECK-NEXT:    [[DOTADDR3_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR3]] to ptr
// CHECK-NEXT:    [[DOTADDR4_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR4]] to ptr
// CHECK-NEXT:    [[DOTADDR5_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR5]] to ptr
// CHECK-NEXT:    [[DOTADDR6_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR6]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 8 [[TMP8]], ptr addrspace(4) align 8 [[TMP7]], i64 16, i1 false)
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META740:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG741:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP1]], ptr [[DOTADDR1_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META742:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR1]]), !dbg [[DBG743:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META744:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR2]]), !dbg [[DBG745:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP3]], ptr [[DOTADDR3_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META746:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR3]]), !dbg [[DBG747:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP4]], ptr [[DOTADDR4_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META748:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR4]]), !dbg [[DBG749:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP5]], ptr [[DOTADDR5_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META750:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR5]]), !dbg [[DBG751:![0-9]+]]
// CHECK-NEXT:    store i32 [[TMP6]], ptr [[DOTADDR6_ASCAST]], align 4
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META752:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR6]]), !dbg [[DBG753:![0-9]+]]
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META754:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG755:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG756:![0-9]+]]
//
__global__ void Test_Kern_ParamRegLimitExpandedStruct(int64_t, int64_t, int64_t, int64_t, int64_t, int64_t, int32_t, StructMultipleElements) {}
// CHECK-LABEL: define dso_local void @_Z39Test_Func_ParamRegLimitUnexpandedStructlllllll22StructMultipleElements
// CHECK-SAME: (i64 [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], i64 [[TMP3:%.*]], i64 [[TMP4:%.*]], i64 [[TMP5:%.*]], i64 [[TMP6:%.*]], ptr addrspace(5) byval([[STRUCT_STRUCTMULTIPLEELEMENTS:%.*]]) align 8 [[TMP7:%.*]]) #[[ATTR0]] !dbg [[DBG757:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR1:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR3:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR4:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR5:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR6:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    [[DOTADDR1_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR1]] to ptr
// CHECK-NEXT:    [[DOTADDR2_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR2]] to ptr
// CHECK-NEXT:    [[DOTADDR3_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR3]] to ptr
// CHECK-NEXT:    [[DOTADDR4_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR4]] to ptr
// CHECK-NEXT:    [[DOTADDR5_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR5]] to ptr
// CHECK-NEXT:    [[DOTADDR6_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR6]] to ptr
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META769:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG770:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP1]], ptr [[DOTADDR1_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META771:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR1]]), !dbg [[DBG772:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META773:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR2]]), !dbg [[DBG774:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP3]], ptr [[DOTADDR3_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META775:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR3]]), !dbg [[DBG776:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP4]], ptr [[DOTADDR4_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META777:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR4]]), !dbg [[DBG778:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP5]], ptr [[DOTADDR5_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META779:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR5]]), !dbg [[DBG780:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP6]], ptr [[DOTADDR6_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META781:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR6]]), !dbg [[DBG782:![0-9]+]]
// CHECK-NEXT:    [[TMP8:%.*]] = addrspacecast ptr addrspace(5) [[TMP7]] to ptr
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META783:![0-9]+]], metadata ptr addrspace(5) [[TMP7]]), !dbg [[DBG784:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG785:![0-9]+]]
//
__device__ void Test_Func_ParamRegLimitUnexpandedStruct(int64_t, int64_t, int64_t, int64_t, int64_t, int64_t, int64_t, StructMultipleElements) {}
// CHECK-LABEL: define dso_local amdgpu_kernel void @_Z39Test_Kern_ParamRegLimitUnexpandedStructlllllll22StructMultipleElements
// CHECK-SAME: (i64 [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], i64 [[TMP3:%.*]], i64 [[TMP4:%.*]], i64 [[TMP5:%.*]], i64 [[TMP6:%.*]], ptr addrspace(4) byref([[STRUCT_STRUCTMULTIPLEELEMENTS:%.*]]) align 8 [[TMP7:%.*]]) #[[ATTR2]] !dbg [[DBG786:![0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[COERCE:%.*]] = alloca [[STRUCT_STRUCTMULTIPLEELEMENTS]], align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR1:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR2:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR3:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR4:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR5:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[DOTADDR6:%.*]] = alloca i64, align 8, addrspace(5)
// CHECK-NEXT:    [[TMP8:%.*]] = addrspacecast ptr addrspace(5) [[COERCE]] to ptr
// CHECK-NEXT:    [[DOTADDR_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR]] to ptr
// CHECK-NEXT:    [[DOTADDR1_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR1]] to ptr
// CHECK-NEXT:    [[DOTADDR2_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR2]] to ptr
// CHECK-NEXT:    [[DOTADDR3_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR3]] to ptr
// CHECK-NEXT:    [[DOTADDR4_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR4]] to ptr
// CHECK-NEXT:    [[DOTADDR5_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR5]] to ptr
// CHECK-NEXT:    [[DOTADDR6_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTADDR6]] to ptr
// CHECK-NEXT:    call void @llvm.memcpy.p0.p4.i64(ptr align 8 [[TMP8]], ptr addrspace(4) align 8 [[TMP7]], i64 16, i1 false)
// CHECK-NEXT:    store i64 [[TMP0]], ptr [[DOTADDR_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META796:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR]]), !dbg [[DBG797:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP1]], ptr [[DOTADDR1_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META798:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR1]]), !dbg [[DBG799:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP2]], ptr [[DOTADDR2_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META800:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR2]]), !dbg [[DBG801:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP3]], ptr [[DOTADDR3_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META802:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR3]]), !dbg [[DBG803:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP4]], ptr [[DOTADDR4_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META804:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR4]]), !dbg [[DBG805:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP5]], ptr [[DOTADDR5_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META806:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR5]]), !dbg [[DBG807:![0-9]+]]
// CHECK-NEXT:    store i64 [[TMP6]], ptr [[DOTADDR6_ASCAST]], align 8
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META808:![0-9]+]], metadata ptr addrspace(5) [[DOTADDR6]]), !dbg [[DBG809:![0-9]+]]
// CHECK-NEXT:    call void @llvm.dbg.def(metadata [[META810:![0-9]+]], metadata ptr addrspace(5) [[COERCE]]), !dbg [[DBG811:![0-9]+]]
// CHECK-NEXT:    ret void, !dbg [[DBG812:![0-9]+]]
//
__global__ void Test_Kern_ParamRegLimitUnexpandedStruct(int64_t, int64_t, int64_t, int64_t, int64_t, int64_t, int64_t, StructMultipleElements) {}
