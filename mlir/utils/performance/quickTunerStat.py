#!/usr/bin/env python3

"""
quickTunerStat.py, script to generate statistics for a given quick tuning 
config generted by quickTunerGen.py. There are two options to "validate" 
results from quickTunerGen.py: using the data generated by quickTunerPreproc.py
and doing a table lookup and running a new tuning loop using rocmlir-tuning-driver
"""
import os
import sys
import shutil
import argparse
import pandas as pd
import numpy as np
from collections import defaultdict
import subprocess
import re
import glob
from dataclasses import dataclass

"""
Validator Base Class
"""
class perfConfigValidator(object):
    """
    base class for validators, implement validate() method
    """
    def __init__(self, name=None):
        self.name = name

    def collectGemmConfigs(self, gemm_config_file, comment='#'):
        """
        collect gemm config files given a gemm_config_file
        """
        gemm_list = []
        with open(gemm_config_file, 'r') as f:
            lines = f.readlines()

        for line in lines:
            if comment is not None:
                line = line.split(comment)[0]

            line = line.strip()
            if line:
                gemm_list.append(line)

        return gemm_list

    def gemmConfigToKey(self, gemm_config):
        """
        Convert gemm line to code
        """
        pattern = r'-transA (\S+) -transB (\S+) -g (\d+) -m (\d+) -n (\d+) -k (\d+)'

        match = re.search(pattern, gemm_config)

        if match:
            tup = match.groups()
            transA = True if tup[0].lower() == 'true' else False
            transB = True if tup[1].lower() == 'true' else False
            return (transA, transB) + tuple([int(x) for x in tup[2:]])
        else:
            print("Could not parse gemmConfig", file=sys.stderr)
            exit(1)
        
        return file_name


    def orderByGemmType(self, input_file=True, normalize=True):
        """
        Creates a dictionary of dictionaries, key by dtype and then gemm, respectively
        """
        def expandPerfConfigs(df):
            df['PerfConfig'] = df['PerfConfig'].str.split(':').str[1]
            
            tile_params = df['PerfConfig'].str.split(',', expand=True).astype(int)
            
            tile_params.columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll', 'param8', 'param9']
                
            tile_params = tile_params.drop(['param8','param9'], axis=1)

            tile_params['performance'] = df['NormalizedTFlops']

            tile_params.replace('N/A', np.nan, inplace=True)

            return tile_params
        
        df = pd.read_csv(input_file, sep='\t')

        df_dir = {}

        trans_cols = ['TransA', 'TransB']

        param_cols = [ 'G', 'M', 'N','K']

        df = df.astype({entry: bool for entry in trans_cols})

        df = df.astype({entry: int for entry in param_cols})
        
        cols = trans_cols + param_cols

        type_dict = {dtype: group for dtype, group in df.groupby('DataType')}

        for dtype in type_dict:
            sub_df = type_dict[dtype]
            
            gemm_df = {gemm: expandPerfConfigs(group) for gemm, group in sub_df.groupby(cols)}

            for gemm in gemm_df:
                gemm_tup = tuple(gemm)
            
                if dtype not in df_dir:
                    df_dir[dtype] = {}
                df_dir[dtype][gemm_tup] = gemm_df[gemm]
                
        self.validation_data = df_dir
        return df_dir            

    def readPerfConfig(self, file_path):
        columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll']
        try:
            df = pd.read_csv(file_path)
            if df.columns[0].startswith('v:'):
                raise ValueError("Detected prefix, not a header.")
            return df
        except ValueError:
            df = pd.read_csv(file_path, header=None)
            df[0] = df[0].apply(lambda x: x.split(':')[1] if isinstance(x, str) and ':' in x else x)
            df.columns = columns
            return df

    def validateFile(self, input_file, dtype=None):
        """
        Method to validate a perf config file for given type
        """
        raise NotImplementedError()

    def validateDir(self, input_dir):
        """
        Method to validate a set of .qt files
        """
        raise NotImplementedError()
            

class dataValidator(perfConfigValidator):
    """
    uses already provided data to validate the configs generated
    """
    def __init__(self, gemm_config_file, preproc_file):
        super().__init__()
        self.gemm_configs = super().collectGemmConfigs(gemm_config_file)
        self.gemm_keys = [super(dataValidator, self).gemmConfigToKey(gemm) for gemm in self.gemm_configs]
        self.preproc_file = preproc_file
        self.validation_data = super().orderByGemmType(self.preproc_file)

    def __typeQtMap(self, input_dir):
        """
        creates a dictionary keyed by qt type with values being
        list of matching qt files
        """        
        qt_files = glob.glob(os.path.join(input_dir, "*.qt"))
        file_dict = {}

        for file in qt_files:
            file_split = os.path.basename(file).split('.')
            file_type = file_split[1]
            method = file_split[0]
            
            if method not in file_dict:
                file_dict[method] = {}
            file_dict[method][file_type] = pd.read_csv(file)
            

        return file_dict

    def compare(self, results, dtype):
        all_data = []
        columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll']
        for gemm in self.gemm_keys:
            gemm = self.__gemmConfigToKey(gemm)
            data_subset = self.validation_data[dtype][gemm]
            results = results[list(columns)]
            merged_df = pd.merge(results, data_subset, on=['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll'], how='left')
            all_data.append(merged_df)

    def validateDir(self, input_dir):
        """
        process whole directory
        """
        quick_tune_data = self.__typeQtMap(input_dir)
        
        output_dict = {}
        for method in quick_tune_data:
            print(f"method {method}")
            for dtype in quick_tune_data[method]:
                print(f"dtype {dtype}")
                if dtype not in output_dict:
                    output_dict[dtype] = {}
                print(f"quick_tune_data {quick_tune_data[method][dtype]}")
                gemm_data = self.validate(quick_tune_data[method][dtype], dtype)
                output_dict[dtype][method] = gemm_data
                """
                ct = 0
                max_values = []
                threshold = 0.92
                for df in gemm_data:
                if (df['performance'].dropna() <= threshold).all():
                #print(f"{name} does not meet threshold (>0.8): {df}")
                    ct += 1
                    #max_values.append(df[column].max())
                output_dict[dtype][method] = ct
            
                self.output_df = pd.DataFrame(output_dict)
                print(self.output_df)
                """
        self.output_dict = output_dict
        return output_dict
        

    def validateFile(self, input_file, dtype=None):
        """
        process single file, if type passed in then we read perf config file
        """
        if not dtype:
            dtype = os.path.basename(input_file).split('.')[1]
            
        df = super().readPerfConfig(input_file)
        return self.validate(df, dtype)        
    
    def validate(self, file_data, dtype):
        # to validate file we need data already read,

        all_data = []
        columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll']
        for gemm in self.gemm_keys:
            data_subset = self.validation_data[dtype][gemm]
            file_data = file_data[columns]
            merged_df = pd.merge(file_data, data_subset, on=['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll'], how='left')
            all_data.append(merged_df)

        return all_data

    def rank(self, threshold=0.9):
        rank_dict = {}
        for dtype in self.output_dict:
            if dtype not in rank_dict:
                rank_dict[dtype] = {}
            for method in self.output_dict[dtype]:
                gemm_data = self.output_dict[dtype][method]
                ct = 0
                for df in gemm_data:
                    if (df['performance'].dropna() <= threshold).all():
                        ct += 1
                    rank_dict[dtype][method] = ct
                    
        self.output_df = pd.DataFrame(rank_dict)
        print(self.output_df)

class tunerValidator(perfConfigValidator):
    """
    MAIN TO DO:
    - get rocmlir running
    - capture output and save to dictionary like DATA is saved
    - do this for all files
    - rank results
    - quickTunerGen.py create a cpp readable file
    """

    
    @dataclass(frozen=True)
    class Options:
        debug: bool
        tuningSpaceKind: str
        quiet: bool
        arch: str
        numCU: int
        rocmlir_gen_flags: str
        verifyMode: str
        tflops: bool
        compact_print: bool

    def __init__(self,
                 gemm_config_file,
                 rocmlir_path,
                 rocm_build_script='/share/scripts/build-rocm'):
        """
        initializer
        """
        self.gemm_configs = super().collectGemmConfigs(gemm_config_file)
        print(self.gemm_configs)
        self.gemm_keys = [super(tunerValidator, self).gemmConfigToKey(gemm) for gemm in self.gemm_configs]
        self.gridwise_gemm_params='rocMLIR/mlir/lib/Dialect/Rock/Tuning/GridwiseGemmParams.cpp'
        
        self.cpp_file = os.path.join(os.path.dirname(rocmlir_path), self.gridwise_gemm_params)
        self.rocm_build_script = rocm_build_script
        self.backup = self.cpp_file + ".bu"
        shutil.copy(self.cpp_file, self.backup)

        

    def __del__(self):
        # copy back original file
        pass

    def __restore_file(self):
        shutil.copy(self.backup, self.cpp_file)

    def updateCppFile(self, df, dtype):
        """
        Update cpp file
        """

        """
        Update cpp file using the dataframe.
        """
        cpp_array = ""
        arr_str = ""
        if dtype == 'f32':
            cpp_array = "PopulateParamsXDL::initParameters[PopulateParamsXDL::nInitParameters] = {\n"
            arr_str = r'PopulateParamsXDL::initParameters\[PopulateParamsXDL::nInitParameters\] = \{.*?\};'
        elif dtype == 'f16':
            cpp_array = "PopulateParamsXDL::initParametersFp16[PopulateParamsXDL::nInitParametersFp16] = {\n"
            arr_str = r'PopulateParamsXDL::initParametersFp16\[PopulateParamsXDL::nInitParametersFp16\] = \{.*?\};'
        elif dtype == 'i8':
            cpp_array = "PopulateParamsXDL::initParametersForward8Bit[PopulateParamsXDL::nInitParametersForward8Bit] = {\n"
            arr_str =  r'PopulateParamsXDL::initParametersForward8Bit\[PopulateParamsXDL::nInitParametersForward8Bit\] = \{.*?\};'
        else:
            print(f"Unrecognized dtype: {dtype}", file=sys.stderr)
            return

        cpp_array += "  // M/block N/block K/block M/wave N/wave kPack splitKFactor forceUnroll bCopyMore\n"

        for _, row in df.iterrows():
            cpp_array += f"  {{{row['M/block']}, {row['N/block']}, {row['K/block']}, {row['M/wave']}, {row['N/wave']}, {row['kPack']}, 1, true, true}},\n"

        cpp_array = cpp_array.rstrip(',\n') + "\n};"

        cpp_filename = self.cpp_file

        with open(cpp_filename, 'r') as file:
            cpp_content = file.read()

        cpp_content = re.sub(arr_str,
                             cpp_array,
                             cpp_content,
                             flags=re.DOTALL
        )

        with open(cpp_filename, 'w') as file:
            file.write(cpp_content)

        """
        
        data = []
        with open(file, 'r') as f:
            header = f.readline().strip()
            if not header[0].isalpha():
                values = header.strip().split(',')
                data.append(values)
            for line in f:
                values = line.strip().split(',')
                data.append(values)

            if dtype == 'f32':            
                cpp_array = "PopulateParamsXDL::initParameters[PopulateParamsXDL::nInitParameters] = {\n"
                arr_str = r'PopulateParamsXDL::initParameters\[PopulateParamsXDL::nInitParameters\] = \{.*?\};'
            elif dtype == 'f16':
                cpp_array = "PopulateParamsXDL::initParametersFp16[PopulateParamsXDL::nInitParametersFp16] = {\n"
                arr_str = r'PopulateParamsXDL::initParametersFp16\[PopulateParamsXDL::nInitParametersFp16\] = \{.*?\};'
            elif dtype == 'i8':
                cpp_array = "PopulateParamsXDL::initParametersForward8Bit[PopulateParamsXDL::nInitParametersForward8Bit] = {\n"
                arr_str =  r'PopulateParamsXDL::initParametersForward8Bit\[PopulateParamsXDL::nInitParametersForward8Bit\] = \{.*?\};'
            else:
                print(f"Unrecognized dtype: {dtype}", file=sys.stderr)
            cpp_array += "  // M/block N/block K/block M/wave N/wave kPack splitKFactor forceUnroll bCopyMore\n"

            for row in data:
                print(row)
                cpp_array += f"  {{{row[0]}, {row[1]}, {row[2]}, {row[3]}, {row[4]}, {row[5]}, 1, true, true}},\n"

            cpp_array = cpp_array.rstrip(',\n') + "\n};"
        
            cpp_filename = self.cpp_file

            with open(cpp_filename, 'r') as file:
                cpp_content = file.read()

            cpp_content = re.sub(arr_str,
                                 cpp_array,
                                 cpp_content,
                                 flags=re.DOTALL
            )

            with open(cpp_filename, 'w') as file:
                file.write(cpp_content)

        """

    def buildRocm(self):
        """
        builds the rocm code base, compiling the code along the way
        """
        result = subprocess.run(self.rocm_build_script, shell=True, capture_output=True, text=True)
    
        if result.returncode != 0:
            print(result.stdout)
            print("Compilation error", file=sys.stderr)
            print(result.stderr)
            exit(1)


    def runTuning(self):
        """
        run rocmlir-tuning-driver on the specified gemm_configs
        returns a list of dataframes representing all perfConfig data collected per gemm config
        """
        configs_path, mlir_build_dir, confClass, options = tuning_params
        paths = perfRunner.create_paths(configs_path, mlir_build_dir)
        datatypes, outputMap = perfRunner.parseDataTypes(dtype)
        print(dtype)
        print(datatypes, outputMap)
        configs = perfRunner.getGemmConfigurations(paths.configuration_file_path, datatypes, outputMap)

        allData = []

        for testVector in configs: # gemm config we iterate through
            # get data for each gemm, using the pre-set config, aggregate values and take best
            commandLine = testVector.split(sep=' ')
            config = confClass.fromCommandLine(commandLine, options.arch, options.numCU)
            config.MLIR_N_REPEATS=1
            testVector = config.toCommandLine()
            print("Tuning:", testVector, file=sys.stderr)
            commandLineOptions = config.generateMlirDriverCommandLine(options.rocmlir_gen_flags)
            print(commandLineOptions)

            # Note, we don't need the -ph, this goes to the tuning driver
            kernelGenCommand = paths.mlir_paths.rocmlir_gen_path + ' ' + commandLineOptions
            print(kernelGenCommand)
            kernelGen = subprocess.Popen(kernelGenCommand.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            tuningLoop = subprocess.Popen(
                [paths.mlir_paths.rocmlir_tuning_driver_path, f"--tuning-space={options.tuningSpaceKind}"],
                stdin=kernelGen.stdout, stdout=subprocess.PIPE, stderr=subprocess.PIPE
            )

            kernelGen.stdout.close()

            #kernelGen stderr
            #kernelGen_stderr = kernelGen.stderr.read()
            #kernelGen.stderr.close()
            #print(f"kernelGen.stderr: {kernelGen_stderr}")

            #tuningloop stderr
            """
            tuningLoop.stdout.close()
            tuningLoop_stderr = tuningLoop.stderr.read()
            tuningLoop.stderr.close()
            print(f"tuningLoop.stderr: {tuningLoop_stderr}")
            """

            # build save file for data
            new_name = configToStr(testVector)
            new_file = os.path.join(path, new_name)
            print(new_file)

            config_data = self.getConfigData(tuningLoop.stdout, config, allData, options, new_file)
            allData.append(config_data)

            #return allData
        print("returning allData")
        return allData    

    def getConfigData(self, tuning_loop, config, allData, options, new_file):
        """
        Take tuning output, put in a dataframe, and order it as it comes out
        save the output to file named by the config data
        config is of the form: -t i8 -out_datatype i32 -transA false -transB false -g 64 -m 1024 -n 384 -k 1024
        perhaps we can parse this and use it to name?
        """
        columns=['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll', 'performance']
        data = []
        for i, result in enumerate(tuningOutput):
            result = result.decode('utf-8')
            result = result.strip()

            if options.debug:
                print(result, file=sys.stderr)
            print(result, file=sys.stderr)

            perfConfig, time = result.split('\t')

            if time == "N/A":
                nanoSeconds = np.nan
                config.setPerfConfig(perfConfig)
                entry = config.tableEntry(nanoSeconds)
                theseTFlops = entry['TFlops']
                print("ENCOUNTERED NAN RESULT")
                #exit(1)
            else:
                nanoSeconds = float(time)

            config.setPerfConfig(perfConfig)
            entry = config.tableEntry(nanoSeconds)
            tflops = entry['TFlops']

            values = perfConfig.split(':')[-1].split(',')
            values = values[:-2]
            values.append(tflops)
            data.append({col: val for col, val in zip(columns, values)})

        # order the dataframe
        df = pd.DataFrame.from_dict(data)
        print(df)
        if df.empty:
            return pd.DataFrame(columns=columns)
        df = df.sort_values(by=['performance'], ascending=False)

        # normalize, allows us to see max perf
        scaler = MinMaxScaler()
        df['performance'] = scaler.fit_transform(df[['performance']])

        # df.to_csv(filename, index=False)
        return df


    def validateDir(self, input_dir):
        """
        process whole directory, adopt for running tuning on said space
        """
        try:
            quick_tune_data = self.__typeQtMap(input_dir)
        
            output_dict = {}
            for method in quick_tune_data:
                print(f"method {method}")
                for dtype in quick_tune_data[method]:

                    # updateCppFile

                    # buildRocm()

                    # run tuning


                    """                
                    print(f"dtype {dtype}")
                    if dtype not in output_dict:
                    output_dict[dtype] = {}
                    print(f"quick_tune_data {quick_tune_data[method][dtype]}")
                    gemm_data = self.validate(quick_tune_data[method][dtype], dtype)
                    output_dict[dtype][method] = gemm_data

                    ct = 0
                    max_values = []
                    threshold = 0.92
                    for df in gemm_data:
                    if (df['performance'].dropna() <= threshold).all():
                    #print(f"{name} does not meet threshold (>0.8): {df}")
                    ct += 1
                    #max_values.append(df[column].max())
                    output_dict[dtype][method] = ct
                
                    self.output_df = pd.DataFrame(output_dict)
                    print(self.output_df)
                    """
            self.output_dict

        except Exception as e:
            print(f"Error occured: {e}", file=sys.stderr)

        finally:
            self.output_dict = output_dict
            self.__restore_file()
            return output_dict

        
    def validateFile(self, input_file, dtype=None):
        """
        process single file, if type passed in then we read perf config file
        """
        try:
            if not dtype:
                dtype = os.path.basename(input_file).split('.')[1]

            # read the input file
            df = super().readPerfConfig(input_file)
            # using self.validation_data, check the data out
            # need to actually run a loop of the rocmlir-tuning-driver
            print(df)
            self.updateCppFile(df, dtype)
            
            self.buildRocm()

            # run the script and get data now

        except Exception as e:
            print(f"Error occured: {e}", file=sys.stderr)

        finally:
            self.__restore_file()
            return self.validate(df, dtype)        
    
    def validate(self, file_data, dtype):
        # to validate file we need data already read,

        all_data = []
        columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll']
        for gemm in self.gemm_keys:
            data_subset = self.validation_data[dtype][gemm]
            file_data = file_data[columns]
            merged_df = pd.merge(file_data, data_subset, on=['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'forceUnroll'], how='left')
            all_data.append(merged_df)

        return all_data


def main(args=None):
    if args is None:
        args = sys.argv[1:]

    parser = argparse.ArgumentParser(prog='quickTunerStat.py',
                                     description='Generated statistics and verify quick tuning configs')

    parser.add_argument('--input-dir',
                        type=str,
                        help='Directory of config files generated by quickTuner')


    parser.add_argument('--qt-file',
                        type=str,
                        help='methodname_type.qt file')

    parser.add_argument('--perfconfig-file',
                        type=str,
                        help='Perf config formatted file')

    parser.add_argument('--dtype',
                        choices=['f32', 'f16', 'i8'],
                        type=str,
                        help='Datatype to be used with perfconfig file (required when --perfconfig-file is specified')

    parser.add_argument('--gemm-configs',
                        type=str,
                        required=True,
                        help='File path for gemm-configs')

    parser.add_argument('--data',
                        type=str,
                        required=True,
                        help='File path for datafile from quickTunerPreproc.py')

    parser.add_argument('--method',
                        choices=['data', 'tuner'],
                        default='data',
                        type=str,
                        help='Method for testing the produced files')
    
    parser.add_argument('--rank',
                        action='store_true',
                        default=False,
                        help='Rank results')

    parser.add_argument('--rocmlir',
                        type=str,
                        help='Path to rocmlir script')
    
    pargs = parser.parse_args()

    print(pargs)

    if pargs.method == 'data':
        verifier = dataValidator(pargs.gemm_configs,
                                     pargs.data)
    elif pargs.method == 'tuner':
        if not pargs.rocmlir:
            raise ValueError(f"rocmlir path not set, please specifiy using --romclir")
        verifier = tunerValidator(pargs.gemm_configs,
                                  pargs.rocmlir)
    else:
        raise ValueError(f"Not a valid method: {method}")

    if pargs.input_dir:
        verifier.validateDir(pargs.input_dir)
        if pargs.rank:
            verifier.rank()

    elif pargs.qt_file:
        verifier.validateFile(pargs.qt_file)

        
    """
    # if single file
    if pargs.input_dir:
        if pargs.method == 'data':
            verifier = dataValidator(pargs.gemm_configs,
                                     pargs.data)
        elif method == 'tuner':
            if not pargs.rocmlir:
                raise ValueError(f"rocmlir path not set, please specifiy using --romclir")
            verifier = tunerValidator(pargs.rocmlir,
                                      pargs.gemm_configs,
                                      pargs.data)
        else:
            raise ValueError(f"Not a valid method: {method}")                                   


    elif pargs.qt_file:
        verifier = dataValidator(pargs.gemm_configs, pargs.data)
        verifier.validateFile(pargs.qt_file)
    elif pargs.perf_config_file:
        if not pargs.type:
            raise Exception(f"type not passed with perf config formatted file: {pargs.perf_config_file}")
        verifier = dataValidator(pargs.gemm_configs, pargs.data)
        verifier.validateFile(pargs.qt_file, pargs.dtype)
    """
        
if __name__ == '__main__':
    main(sys.argv[1:])
