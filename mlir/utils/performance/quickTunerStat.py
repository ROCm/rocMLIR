#!/usr/bin/env python3

"""
quickTunerStat.py, script to generate statistics for a given quick tuning 
config generted by quickTunerGen.py. There are two options to "validate" 
results from quickTunerGen.py: using the data generated by quickTunerPreproc.py
and doing a table lookup and running a new tuning loop using rocmlir-tuning-driver

Example usage:

python3 quickTunerStat.py --qt-file method.type.qt --data combined_data --gemm-configs gemms --method data --rank 

Will use the perf configs specified in method.type.qt (generated with quickTunerGen.py) and for each gemm in gemms, lookups the performance from comined_data (generated with quickTunerPreproc.py).
"""

import os
import sys
import shutil
import argparse
import pandas as pd
import numpy as np
from collections import defaultdict
import subprocess
import re
import glob
from dataclasses import dataclass
from perfCommonUtils import Operation
import perfRunner
from sklearn.preprocessing import MinMaxScaler

"""
Validator Base Class
"""
class PerfConfigValidator():
    """
    base class for validators, implement validate() method
    """
    def __init__(self, name=None):
        self.name = name

    def collectGemmConfigs(self, gemm_config_file, comment='#'):
        """
        collect gemm config files given a gemm_config_file
        """
        gemm_list = []
        with open(gemm_config_file, 'r') as f:
            lines = f.readlines()
        for line in lines:
            if comment is not None:
                line = line.split(comment)[0]
            line = line.strip()
            if line:
                gemm_list.append(line)
        return gemm_list

    def gemmConfigToKey(self, gemm_config):
        """
        Convert gemm line to code
        """
        pattern = r'-transA (\S+) -transB (\S+) -g (\d+) -m (\d+) -n (\d+) -k (\d+)'
        match = re.search(pattern, gemm_config)
        if match:
            tup = match.groups()
            transA = (tup[0].lower() in ['1','true']) 
            transB = (tup[1].lower() in ['1','true'])
            return (transA, transB) + tuple([int(x) for x in tup[2:]])
        else:
            print("Could not parse gemmConfig", file=sys.stderr)
            exit(1)
        return file_name

    def orderByGemmType(self, input_file=True, normalize=True):
        """
        Creates a dictionary of dictionaries, key by dtype and then gemm, respectively
        """
        def expandPerfConfigs(df):
            df['PerfConfig'] = df['PerfConfig'].str.split(':').str[1]
            tile_params = df['PerfConfig'].str.split(',', expand=True).astype(int)            
            tile_params.columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'splitK','forceUnroll', 'bCopyMore']                
            #tile_params = tile_params.drop(['param9'], axis=1)
            tile_params['performance'] = df['NormalizedTFlops']
            tile_params.replace('N/A', np.nan, inplace=True)
            return tile_params
        
        df = pd.read_csv(input_file, sep='\t')
        df_dir = {}
        trans_cols = ['TransA', 'TransB']
        param_cols = [ 'G', 'M', 'N','K']
        df = df.astype({entry: bool for entry in trans_cols})
        df = df.astype({entry: int for entry in param_cols})      
        cols = trans_cols + param_cols
        type_dict = {dtype: group for dtype, group in df.groupby('DataType')}
        for dtype in type_dict:
            sub_df = type_dict[dtype]
            gemm_df = {gemm: expandPerfConfigs(group) for gemm, group in sub_df.groupby(cols)}
            for gemm in gemm_df:
                gemm_tup = tuple(gemm)            
                if dtype not in df_dir:
                    df_dir[dtype] = {}
                df_dir[dtype][gemm_tup] = gemm_df[gemm]
        self.validation_data = df_dir
        return df_dir            

    def readPerfConfig(self, file_path):
        columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'splitK', 'forceUnroll', 'bCopyMore']
        try:
            df = pd.read_csv(file_path)
            if df.columns[0].startswith('v:'):
                raise ValueError("Detected prefix, not a header.")
            return df
        except ValueError:
            df = pd.read_csv(file_path, header=None)
            df[0] = df[0].apply(lambda x: x.split(':')[1] if isinstance(x, str) and ':' in x else x)
            df.columns = columns
            return df

    def saveCpp(self, df, dtype):
        cols = df.columns
        if 'forceUnroll' in cols:
            df['forceUnroll'] = df['forceUnroll'].astype(bool)
        else:
            df['forceUnroll'] = True
        if 'bCopyMore' in cols:
            df['bCopyMore'] = df['bCopyMore'].astype(bool)
        else:
            df['bCopyMore'] = True
        cpp_array = "{\n"
        with open(f"quick_tuning_{dtype}_cpp", 'w') as file:
            for _, row in df.iterrows():
                cpp_array += f"  {{{row['M/block']}, {row['N/block']}, {row['K/block']}, {row['M/wave']}, {row['N/wave']}, {row['kPack']}, {row['splitK']}, {row['forceUnroll']}, {row['bCopyMore']}}},\n"
            cpp_array = cpp_array.rstrip(',') + "};"
            file.write(cpp_array)
            
        

    def validateFile(self, input_file, dtype=None):
        """
        Method to validate a perf config file for given type
        """
        raise NotImplementedError()

    def validateDir(self, input_dir):
        """
        Method to validate a set of .qt files
        """
        raise NotImplementedError()
            

class DataValidator(PerfConfigValidator):
    """
    uses already provided data to validate the configs generated
    """
    def __init__(self, gemm_config_file, preproc_file, debug=False):
        super().__init__()
        self.gemm_configs = super().collectGemmConfigs(gemm_config_file)
        self.gemm_keys = [super(DataValidator, self).gemmConfigToKey(gemm) for gemm in self.gemm_configs]
        self.preproc_file = preproc_file
        self.validation_data = super().orderByGemmType(self.preproc_file)
        self.debug = debug

    def __typeQtMap(self, input_dir):
        """
        creates a dictionary keyed by qt type with values being
        list of matching qt files
        """        
        qt_files = glob.glob(os.path.join(input_dir, "*.qt"))
        file_dict = {}

        for file in qt_files:
            file_split = os.path.basename(file).split('.')
            file_type = file_split[1]
            method = file_split[0]
            
            if method not in file_dict:
                file_dict[method] = {}
            file_dict[method][file_type] = pd.read_csv(file)
            
        return file_dict

    def compare(self, results, dtype):
        all_data = []
        columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack','splitK', 'forceUnroll','bCopyMore']
        for gemm in self.gemm_keys:
            gemm = self.__gemmConfigToKey(gemm)
            data_subset = self.validation_data[dtype][gemm]
            results = results[list(columns)]
            merged_df = pd.merge(results, data_subset, on=['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'splitK', 'forceUnroll','bCopyMore'], how='left')
            all_data.append(merged_df)

    def validateDir(self, input_dir):
        """
        process whole directory
        """
        self.quick_tune_data = self.__typeQtMap(input_dir)
        
        output_dict = {}
        for method in self.quick_tune_data:
            if self.debug:
                print(f"method {method}")
            for dtype in self.quick_tune_data[method]:
                if self.debug:
                    print(f"dtype {dtype}")
                if dtype not in self.validation_data:
                    continue
                if dtype not in output_dict:
                    output_dict[dtype] = {}
                if self.debug:
                    print(f"quick_tune_data {self.quick_tune_data[method][dtype]}")    
                gemm_data = self.validate(self.quick_tune_data[method][dtype], dtype)
                output_dict[dtype][method] = gemm_data
        self.output_dict = output_dict
        return output_dict
        
    def validateFile(self, input_file, dtype=None):
        """
        process single file, if type passed in then we read perf config file
        """
        if not dtype:
            dtype = os.path.basename(input_file).split('.')[1]
        df = super().readPerfConfig(input_file)
        return self.validate(df, dtype)        
    
    def validate(self, file_data, dtype):
        # to validate file we need data already read,

        all_data = []
        columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'splitK', 'forceUnroll', 'bCopyMore']
        #print(dtype)
        #print(self.validation_data[dtype])
        for gemm in self.gemm_keys:
            if gemm not in self.validation_data[dtype]:
                continue
            data_subset = self.validation_data[dtype][gemm]
            file_data = file_data[columns]
            merged_df = pd.merge(file_data, data_subset, on=['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'splitK', 'forceUnroll', 'bCopyMore'], how='left')
            all_data.append(merged_df)
        return all_data

    def rank(self, threshold=0.9):
        rank_dict = {}
        for dtype in self.output_dict:
            if dtype not in rank_dict:
                rank_dict[dtype] = {}
            for method in self.output_dict[dtype]:
                gemm_data = self.output_dict[dtype][method]
                ct = 0
                for df in gemm_data:
                    if (df['performance'].dropna() <= threshold).all():
                        ct += 1
                    rank_dict[dtype][method] = ct
        self.output_df = pd.DataFrame(rank_dict)
        df = self.output_df
        min_values = df.min()
        best_methods = df.idxmin()
        method_counts = best_methods.value_counts()
        max_count = method_counts.max()
        majority_methods = method_counts[method_counts == max_count].index
        result_methods = {}
        for col in df.columns:
            candidates = df.loc[majority_methods, col]
            result_methods[col] = candidates.idxmin()
        # Create a list of tuples with index and corresponding method
        output = [(index, method) for index, method in result_methods.items()]        
        for entry in output:
            dtype, method = entry
            df = self.quick_tune_data[method][dtype]
            df.to_csv(f"quick_tuning_{dtype}", index=False)
            super().saveCpp(df, dtype)
        print(self.output_df)
            
            
class TunerValidator(PerfConfigValidator):
    """
    This uses perfRunner functions to run the rocmlir-tuning-driver
    and collect the resulting run data. It will edit the GridwiseGemmsParams.cpp
    with the correct perfConfig, compile rocmlir-tuning-driver, and run it. 
    Restoring the file when done.
    """
    @dataclass(frozen=True)
    class Options:
        debug: bool
        tuningSpaceKind: str
        quiet: bool
        arch: str
        numCU: int
        rocmlir_gen_flags: str
        verifyMode: str
        tflops: bool
        compact_print: bool

    def __init__(self,
                 gemm_config_file,
                 rocmlir_path,
                 rocm_build_script='/share/scripts/build-rocm',
                 debug=False):
        self.gemm_configs = super().collectGemmConfigs(gemm_config_file)
        print(self.gemm_configs)
        self.gemm_keys = [super(TunerValidator, self).gemmConfigToKey(gemm) for gemm in self.gemm_configs]
        self.gridwise_gemm_params='rocMLIR/mlir/lib/Dialect/Rock/Tuning/GridwiseGemmParams.cpp'
        self.cpp_file = os.path.join(os.path.dirname(rocmlir_path), self.gridwise_gemm_params)
        self.rocm_build_script = rocm_build_script
        self.backup = self.cpp_file + "~"
        shutil.copy(self.cpp_file, self.backup) # create backup
        self.archNames = perfRunner.getArch()
        self.arch = ','.join(self.archNames)
        self.numCU = perfRunner.getNumCU(perfRunner.getChip())
        self.root_dir = str(subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).decode().strip())
        self.default_conv_configs = self.root_dir + '/mlir/utils/jenkins/performance/conv-configs'
        self.rocmlir_gen_flags = ''
        self.opType = Operation.fromName('gemm')
        self.configs_path = gemm_config_file
        self.mlir_build_dir = perfRunner.find_mlir_build_dir()
        self.paths = perfRunner.create_paths(self.configs_path, self.mlir_build_dir)
        
        if not self.paths.mlir_paths:
            raise RuntimeError("MLIR build dir was not found")
    
        self.options = TunerValidator.Options(arch=self.arch, numCU=self.numCU, debug=False,
                      quiet=False,
                      tuningSpaceKind="quick",
                      rocmlir_gen_flags=self.rocmlir_gen_flags,
                      verifyMode="gpu",
                      tflops=True,
                      compact_print=False)
        
        self.confClass = perfRunner.GemmConfiguration
        self.debug = debug

    def __restore_file(self):
        shutil.copy(self.backup, self.cpp_file)

    def updateCppFile(self, df, dtype):
        """
        Update cpp file with data from dataframe
        """
        cpp_array = ""
        arr_str = ""
        if dtype == 'f32':
            cpp_array = "PopulateParamsXDL::initParameters[PopulateParamsXDL::nInitParameters] = {\n"
            arr_str = r'PopulateParamsXDL::initParameters\[PopulateParamsXDL::nInitParameters\] = \{.*?\};'
        elif dtype == 'f16':
            cpp_array = "PopulateParamsXDL::initParametersFp16[PopulateParamsXDL::nInitParametersFp16] = {\n"
            arr_str = r'PopulateParamsXDL::initParametersFp16\[PopulateParamsXDL::nInitParametersFp16\] = \{.*?\};'
        elif dtype == 'i8':
            cpp_array = "PopulateParamsXDL::initParametersForward8Bit[PopulateParamsXDL::nInitParametersForward8Bit] = {\n"
            arr_str =  r'PopulateParamsXDL::initParametersForward8Bit\[PopulateParamsXDL::nInitParametersForward8Bit\] = \{.*?\};'
        else:
            print(f"Unrecognized dtype: {dtype}", file=sys.stderr)
            return
        cpp_array += "  // M/block N/block K/block M/wave N/wave kPack splitKFactor forceUnroll bCopyMore\n"
        for _, row in df.iterrows():
            cpp_array += f"  {{{row['M/block']}, {row['N/block']}, {row['K/block']}, {row['M/wave']}, {row['N/wave']}, {row['kPack']}, 1, true, true}},\n"

        cpp_array = cpp_array.rstrip(',\n') + "\n};"
        cpp_filename = self.cpp_file
        with open(cpp_filename, 'r') as file:
            cpp_content = file.read()
        cpp_content = re.sub(arr_str,
                             cpp_array,
                             cpp_content,
                             flags=re.DOTALL
        )
        with open(cpp_filename, 'w') as file:
            file.write(cpp_content)

    def buildRocm(self):
        """
        builds the rocm code base, compiling the code along the way
        """
        result = subprocess.run(self.rocm_build_script, shell=True, capture_output=True, text=True)
    
        if result.returncode != 0:
            print(result.stdout)
            print("Compilation error", file=sys.stderr)
            print(result.stderr)
            exit(1)

    def runTuning(self, dtype):
        """
        run rocmlir-tuning-driver on the specified gemm_configs
        returns a list of dataframes representing all perfConfig data collected per gemm config
        """        
        datatypes, outputMap = perfRunner.parseDataTypes(dtype)
        if self.debug:
            print(dtype)
            print(datatypes, outputMap)
        configs = perfRunner.getGemmConfigurations(self.paths.configuration_file_path, datatypes, outputMap)
        if self.debug:
            print(configs)

        allData = []

        for testVector in configs: # gemm config we iterate through
            # get data for each gemm, using the pre-set config, aggregate values and take best
            commandLine = testVector.split(sep=' ')
            config = self.confClass.fromCommandLine(commandLine, self.options.arch, self.options.numCU)
            config.MLIR_N_REPEATS=1
            testVector = config.toCommandLine()
            print("Tuning:", testVector, file=sys.stderr)
            commandLineOptions = config.generateMlirDriverCommandLine(self.options.rocmlir_gen_flags)
            print(commandLineOptions)
            # Note, we don't need the -ph, this goes to the tuning driver
            kernelGenCommand = self.paths.mlir_paths.rocmlir_gen_path + ' ' + commandLineOptions
            print(kernelGenCommand)
            kernelGen = subprocess.Popen(kernelGenCommand.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            tuningLoop = subprocess.Popen(
                [self.paths.mlir_paths.rocmlir_tuning_driver_path, f"--tuning-space={self.options.tuningSpaceKind}"],
                stdin=kernelGen.stdout, stdout=subprocess.PIPE, stderr=subprocess.PIPE
            )
            kernelGen.stdout.close()
            config_data = self.getConfigData(tuningLoop.stdout, config, allData, self.options)
        return allData    

    def getConfigData(self, tuning_loop, config, allData, options):
        """
        Take tuning output, put in a dataframe, and order it as it comes out
        save the output to file named by the config data
        config is of the form: -t i8 -out_datatype i32 -transA false -transB false -g 64 -m 1024 -n 384 -k 1024
        perhaps we can parse this and use it to name?
        """
        columns=['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'splitK', 'forceUnroll','bCopyMore', 'performance']
        data = []
        for i, result in enumerate(tuning_loop):
            result = result.decode('utf-8')
            result = result.strip()
            perfConfig, time = result.split('\t')
            if time == "N/A":
                nanoSeconds = np.nan
                config.setPerfConfig(perfConfig)
                entry = config.tableEntry(nanoSeconds)
                theseTFlops = entry['TFlops']
            else:
                nanoSeconds = float(time)
            config.setPerfConfig(perfConfig)
            entry = config.tableEntry(nanoSeconds)
            tflops = entry['TFlops']
            values = perfConfig.split(':')[-1].split(',')
            values = values[:-2]
            values.append(tflops)
            data.append({col: val for col, val in zip(columns, values)})
        df = pd.DataFrame.from_dict(data)
        print(df)
        if df.empty:
            return pd.DataFrame(columns=columns)
        # dont want this, instead we want OG data's values to comare
        # with
        df = df.sort_values(by=['performance'], ascending=False)
        scaler = MinMaxScaler()
        df['performance'] = scaler.fit_transform(df[['performance']])
        return df

    def validateDir(self, input_dir): # currently disabled
        """
        process whole directory, adopt for running tuning on said space
        """
        pass
        try:
            self.quick_tune_data = self.__typeQtMap(input_dir)        
            output_dict = {}
            for method in self.quick_tune_data:
                print(f"method {method}")
                for dtype in self.quick_tune_data[method]: 
                    df = super().readPerfConfig(input_file)
                    self.updateCppFile(df, dtype)
                    self.runTuning([dtype])
            self.output_dict
        except Exception as e:
            print(f"Error occured: {e}", file=sys.stderr)
        finally:
            self.output_dict = output_dict
            self.__restore_file()
            return output_dict
        
    def validateFile(self, input_file, dtype=None):
        """
        process single file, if type passed in then we read perf config file
        """
        try:
            if not dtype:
                dtype = os.path.basename(input_file).split('.')[1]
            df = super().readPerfConfig(input_file)
            self.updateCppFile(df, dtype)
            self.runTuning([dtype])
        except Exception as e:
            print(f"Error occured: {e}", file=sys.stderr)
        finally:
            self.__restore_file()
    
    def validate(self, file_data, dtype):
        all_data = []
        columns = ['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'splitK','forceUnroll', 'bCopyMore']
        for gemm in self.gemm_keys:
            data_subset = self.validation_data[dtype][gemm]
            file_data = file_data[columns]
            merged_df = pd.merge(file_data, data_subset, on=['M/block', 'N/block', 'K/block', 'M/wave', 'N/wave', 'kPack', 'splitK', 'forceUnroll', 'bCopyMore'], how='left')
            all_data.append(merged_df)
        return all_data


def main(args=None):
    if args is None:
        args = sys.argv[1:]

    parser = argparse.ArgumentParser(prog='quickTunerStat.py',
                                     description='Generated statistics and verify quick tuning configs')

    parser.add_argument('--input-dir',
                        type=str,
                        help='Directory of config files generated by quickTuner')


    parser.add_argument('--qt-file',
                        type=str,
                        help='methodname_type.qt file')

    parser.add_argument('--perfconfig-file',
                        type=str,
                        help='Perf config formatted file')

    parser.add_argument('--dtype',
                        choices=['f32', 'f16', 'i8'],
                        type=str,
                        help='Datatype to be used with perfconfig file (required when --perfconfig-file is specified')

    parser.add_argument('--gemm-configs',
                        type=str,
                        required=True,
                        help='File path for gemm-configs')

    parser.add_argument('--data',
                        type=str,
                        required=True,
                        help='File path for datafile from quickTunerPreproc.py')

    parser.add_argument('--method',
                        choices=['data', 'tuner'],
                        default='data',
                        type=str,
                        help='Method for testing the produced files')
    
    parser.add_argument('--rank',
                        action='store_true',
                        default=False,
                        help='Rank results')

    parser.add_argument('--rocmlir',
                        type=str,
                        help='Path to rocmlir script')

    parser.add_argument('--debug',
                        action='store_true',
                        default=False,
                        help='Print debug info')
    
    pargs = parser.parse_args()

    if pargs.debug:        
        print(pargs)

    if pargs.method == 'data':
        verifier = DataValidator(pargs.gemm_configs,
                                 pargs.data,
                                 debug=pargs.debug)
    elif pargs.method == 'tuner':
        raise NotImplementedError()
        if not pargs.rocmlir:
            raise ValueError(f"rocmlir path not set, please specifiy using --romclir")
        verifier = TunerValidator(pargs.gemm_configs,
                                  pargs.rocmlir,
                                  debug=pargs.debug)
    else:
        raise ValueError(f"Not a valid method: {method}")

    if pargs.input_dir:
        verifier.validateDir(pargs.input_dir)
        if pargs.rank:
            verifier.rank()

    elif pargs.qt_file:
        verifier.validateFile(pargs.qt_file)

               
if __name__ == '__main__':
    main(sys.argv[1:])
