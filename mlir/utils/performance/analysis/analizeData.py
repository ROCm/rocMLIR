# This script requires data generated by gatherTuningData.sh
# Quick tuning DB can be generated by:
# $ python analizeData.py
# The data will be created in quick_tuning_i8, quick_tuning_f16, quick_tuning_f32 files

import sys
import argparse
import glob
import pandas as pd

#Retrive a specific item from a dictionary
def get_value(data_dict, data_type, perfconfig):
    try:
        return data_dict[data_type][perfconfig]
    except KeyError:
        return None

#Merging conv and gemm result data
def merge_dicts(dict1, dict2):
    for datatype, configs in dict2.items():
        if datatype not in dict1:
            dict1[datatype] = configs
        else:
            for config, values in configs.items():
                if config not in dict1[datatype]:
                    dict1[datatype][config] = values
                else:
                    dict1[datatype][config]['count'] += values['count']
    return dict1

#Add averge tflops to wining perfconfigs
def add_average_tflops(counted_perf,avrg_tflops):
    for datatype, value in counted_perf.items():
        for perfconfig, perf_value in value.items():
            avg_value = get_value(avrg_tflops, datatype, perfconfig)
            perf_value['tflops'] = avg_value

#Get the perfconfig with the maximum TFLOPs
def get_max_tflops_perfconfig(group):
        max_row = group.loc[group['TFlops'].idxmax()]
        return max_row['PerfConfig']

def analizeData(operation):
    tsv_files = pd.DataFrame()
    if operation == "conv":
        tsv_files = glob.glob('conv/tunedData/*.debug')
    elif operation == 'gemm':
        tsv_files = glob.glob('gemm/tunedData/*.debug')
    else:
        raise Exception("Operation not recognized")
    dfs = []

    for file in tsv_files:
        df = pd.read_csv(file, sep='\t')
        dfs.append(df)
    final_df = pd.concat(dfs, ignore_index=True)
    unique_data_types = final_df['DataType'].unique()
    #Iterate through unique data type
    results = {}
    for data_type in unique_data_types:
        current_df = final_df[final_df['DataType'] == data_type]
        problem_cols = []
        #Determine the problem columns based on operation type
        if operation == "conv":
            problem_cols = ['N', 'C', 'K', 'Y', 'X', 'DilationH', 'DilationW', 'StrideH', 'StrideW', 'PaddingH', 'PaddingW' ]
        elif operation == 'gemm':
            problem_cols = ['TransA', 'TransB', 'G', 'M', 'K', 'N']
        else:
            raise Exception("Operation not recognized")
        grouped = current_df.groupby(problem_cols)
        win_counts = {}
        #Iterate through the grouped DataFrame
        for name, group_df in grouped:
            max_tflops_perfconfig = get_max_tflops_perfconfig(group_df)
            #Increases the counter for the winning perfconfig
            if max_tflops_perfconfig not in win_counts:
                win_counts[max_tflops_perfconfig] = {'count': 0, 'tflops': 0}
            win_counts[max_tflops_perfconfig]['count'] += 1
        results[data_type] = win_counts
    return results

def averagePerformance():
    conv_files = glob.glob('conv/tunedData/*.debug')
    gemm_files = glob.glob('gemm/tunedData/*.debug')
    tsv_files = conv_files + gemm_files
    dfs = []

    for file in tsv_files:
        df = pd.read_csv(file, sep='\t')
        dfs.append(df)
    final_df = pd.concat(dfs, ignore_index=True)
    unique_data_types = final_df['DataType'].unique()
    result = {}
    #Iterating through unique data types
    for data_type in unique_data_types:
        current_df = final_df[final_df['DataType'] == data_type]
        fgroups = current_df.groupby('PerfConfig')
        not_nan_counts = {}
        mean_tflops = {}
        problems_count = 0
        #Iterating through perconfigs in gruped DataFrame
        for perfconfig, group_df in fgroups:
            problems_count = len(group_df)
            not_nan_count = pd.notna(group_df['TFlops']).sum()
            not_nan_counts[perfconfig] = not_nan_count
            mean_tflops[perfconfig] = group_df['TFlops'].mean()
        sorted_counts = sorted(not_nan_counts.items(), key=lambda x: x[1], reverse=True)
        #Filtering configurations that can be applied on all problems
        top_perfconfigs = {perfconfig: mean_tflops[perfconfig] for perfconfig, count in sorted_counts if count == problems_count}
        result[data_type] = top_perfconfigs
    return result

# Main function.
def main(args=None):
    """
    usage: python3 analizeData.py

    """

    counted_win_gemm = analizeData("gemm")
    counted_win_conv = analizeData("conv")
    avrg_tfops_per_datatype = averagePerformance()

    add_average_tflops(counted_win_gemm,avrg_tfops_per_datatype)
    add_average_tflops(counted_win_conv,avrg_tfops_per_datatype)

    merged_data = merge_dicts(counted_win_gemm, counted_win_conv)
    sorted_data = {}
    for datatype, configs in merged_data.items():
        # Sort the configs dictionary by 'count' and 'tflops'
        sorted_configs = dict(sorted(configs.items(), key=lambda item: (-item[1]['count'], -item[1]['tflops'])))
        sorted_data[datatype] = sorted_configs

    for datatype, value in sorted_data.items():
        output_file = f"quick_tuning_{datatype}"
        with open(output_file, 'w') as f:
            for perfconfig, perf_value in value.items():
                f.write(f"{perfconfig}\n")

if __name__ == '__main__':
    sys.exit(main())
