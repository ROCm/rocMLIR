# This script requires tuning data generated by gatherTuningData.sh
# Quick tuning DB can be generated by:
# $ python analizeData.py -p [data_path]
# The output data will be created in quick_tuning_i8, quick_tuning_f16, quick_tuning_f32 files

import sys
import argparse
import glob
import pandas as pd

# Retrive a specific item from a dictionary
def get_value(data_dict, data_type, perfconfig):
    try:
        return data_dict[data_type][perfconfig]
    except KeyError:
        return -1

# Add averge tflops to wining perfconfigs
def add_average_tflops(counted_perf,avrg_tflops):
    for datatype, value in counted_perf.items():
        for perfconfig, perf_value in value.items():
            avg_value = get_value(avrg_tflops, datatype, perfconfig)
            perf_value['tflops'] = avg_value

# Get the perfconfig with the maximum TFLOPs
def get_max_tflops_perfconfig(group):
    max_index = group['TFlops'].idxmax()
    max_row = group.loc[max_index]
    perf_config = max_row['PerfConfig']
    group.drop(max_index, inplace=True)
    return perf_config

def analizeData(data_path, avrg_tfops_per_datatype):
    tsv_files = pd.DataFrame()
    tsv_files = glob.glob(f"{data_path}/**/*.debug", recursive=True)
    dfs = []
    for file in tsv_files:
        df = pd.read_csv(file, sep='\t')
        dfs.append(df)
    final_df = pd.concat(dfs, ignore_index=True)
    unique_data_types = final_df['DataType'].unique()
    # Iterate through unique data type
    results = {}
    operations = ['conv', 'gemm']
    for data_type in unique_data_types:
        win_counts = {}
        for operation in operations:
            current_df = final_df[final_df['DataType'] == data_type]
            problem_cols = []
            # Determine the problem columns based on operation type
            if operation == "conv":
                problem_cols = ['N', 'C', 'K', 'Y', 'X', 'DilationH', 'DilationW', 'StrideH', 'StrideW', 'PaddingH', 'PaddingW']
            elif operation == 'gemm':
                problem_cols = ['TransA', 'TransB', 'G', 'M', 'K', 'N']
            else:
                raise Exception("Operation not recognized")
            grouped = current_df.groupby(problem_cols)
            # Iterate through the grouped DataFrame
            for name, group_df in grouped:
                avg_value = -1
                max_tflops_perfconfig = {}
                # Checking if the perfconfig is applicable to all tuned problems
                while avg_value == -1:
                    max_tflops_perfconfig = get_max_tflops_perfconfig(group_df)
                    avg_value = get_value(avrg_tfops_per_datatype, data_type, max_tflops_perfconfig)
                if max_tflops_perfconfig not in win_counts:
                    win_counts[max_tflops_perfconfig] = {'count': 0, 'tflops': 0}
                win_counts[max_tflops_perfconfig]['count'] += 1
            results[data_type] = win_counts
    return results

def averagePerformance(data_path):
    tsv_files = glob.glob(f"{data_path}/**/*.debug", recursive=True)
    dfs = []
    for file in tsv_files:
        df = pd.read_csv(file, sep='\t')
        dfs.append(df)
    final_df = pd.concat(dfs, ignore_index=True)
    unique_data_types = final_df['DataType'].unique()
    result = {}
    # Iterating through unique data types
    for data_type in unique_data_types:
        current_df = final_df[final_df['DataType'] == data_type]
        fgroups = current_df.groupby('PerfConfig')
        not_nan_counts = {}
        mean_tflops = {}
        problems_count = 0
        # Iterating through perconfigs in gruped DataFrame
        for perfconfig, group_df in fgroups:
            if problems_count < len(group_df):
                problems_count = len(group_df)
            not_nan_count = pd.notna(group_df['TFlops']).sum()
            not_nan_counts[perfconfig] = not_nan_count
            mean_tflops[perfconfig] = group_df['TFlops'].mean()
        sorted_counts = sorted(not_nan_counts.items(), key=lambda x: x[1], reverse=True)
        # Filtering configurations that can be applied on all problems
        top_perfconfigs = {perfconfig: mean_tflops[perfconfig] for perfconfig, count in sorted_counts if count == problems_count}
        result[data_type] = top_perfconfigs
    return result

# Main function.
def main(args=None):
    """
    usage: python3 analizeData.py 

    """
    parser = argparse.ArgumentParser()
    parser.add_argument("-p", "--path",
        type=str,
        default="data",
        help="Path to the directory that contains tuning data.")

    parser.add_argument("-d", "--debug",
        action='store_true',
        default=False,
        help="Add additional information to the output file.")
    parsed_args = parser.parse_args(args)

    data_path = parsed_args.path
    debug = parsed_args.debug

    avrg_tfops_per_datatype = averagePerformance(data_path)
    counted_win = analizeData(data_path, avrg_tfops_per_datatype)
    add_average_tflops(counted_win,avrg_tfops_per_datatype)

    sorted_data = {}
    for datatype, configs in counted_win.items():
        # Sort the configs dictionary by 'count' and 'tflops'
        sorted_configs = dict(sorted(configs.items(), key=lambda item: (-item[1]['count'], -item[1]['tflops'])))
        sorted_data[datatype] = sorted_configs

    for datatype, value in sorted_data.items():
        output_file = f"quick_tuning_{datatype}"
        with open(output_file, 'w') as f:
            for perfconfig, perf_value in value.items():
                f.write(perfconfig)
                if debug:
                    f.write(f" count: {perf_value['count']}, tflops: {perf_value['tflops']}")
                f.write("\n")

if __name__ == '__main__':
    sys.exit(main())
