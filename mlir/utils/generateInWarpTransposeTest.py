#!/usr/bin/env python3

from collections import namedtuple
from typing import List
import os
import shutil
import subprocess
import sys

TestSpec = namedtuple('TestSpec', ['size', 'perm', 'name'])
DEFAULT_SPECS: List[TestSpec] = [TestSpec(4, [0, 1, 2, 3], "tr_4x4"),
    TestSpec(2, [0, 1, 2, 3], "tr_2x2"),
    TestSpec(2, [0, 2, 1, 3], "tr_2x2_0213")]


def testHeader() -> str:
    ret = """// ### DO NOT EDIT ###
// Generated by mlir/utils/generateInWarpTransposeTest.py

// RUN: rocmlir-opt \\
// RUN: --rock-sugar-to-loops --rock-loops-to-cf --convert-rock-to-gpu %s \\
// RUN:  | rocmlir-driver --arch %arch --kernel-pipeline binary --host-pipeline runner \\
// RUN:  | mlir-cpu-runner -O2 \\
// RUN: --shared-libs=%linalg_test_lib_dir/libmlir_rocm_runtime%shlibext,%conv_validation_wrapper_library_dir/libconv-validation-wrappers%shlibext,%linalg_test_lib_dir/%prefix_mlir_runner_utils%shlibext \\
// RUN: --entry-point-result=i32 | FileCheck %s

// CHECK: {{^}}0{{$}}
    """
    return ret

def gpuCode(spec: TestSpec) -> str:
    """Generates the gpu-side code for calling a particular inWarpTranspose test"""
    ret = [f"""
func.func @{spec.name}_kern(%arg0: memref<1024xi32>, %arg1: memref<1024xi32>) -> ()
attributes {{block_size = 64 : i32, grid_size = 64 : i32, kernel = 0 : i32}} {{
  %cst0 = arith.constant 0 : index
  %cst0_i32 = arith.constant 0 : i32
  %cst1 = arith.constant 1 : index
  %cst16 = arith.constant 16 : index
  %cst64 = arith.constant 64 : index
  %cst64_i32 = arith.constant 64 : i32

  %workitem = gpu.thread_id x
  %tid = arith.remui %workitem, %cst64 : index
  %vec_0 = arith.constant dense<-1> : vector<16xi32>"""]
    for i in range(16):
        if i != 0:
            ret.append(f"%cst{i}_i32 = arith.constant {i} : i32")
        load_idx = "%tid" if i == 0 else f"%load_idx_{i}"
        ret.append(f"""
%v_{i} = memref.load %arg0[{load_idx}] : memref<1024xi32>
%vec_{i+1} = vector.insertelement %v_{i}, %vec_{i}[ %cst{i}_i32 : i32 ] : vector<16xi32>
%load_idx_{i+1} = arith.addi {load_idx}, %cst64 : index""")
    ret.append(f"""gpu.barrier
%transposed = rock.in_warp_transpose {{ size = {spec.size} : i32,
  inGroupPerm = [ {', '.join(str(i) + " : i32" for i in spec.perm)}] }} %vec_16, %tid
  : vector<16xi32>, index
gpu.barrier""")
    for i in range(16):
        store_idx = "%tid" if i == 0 else f"%store_idx_{i}"
        ret.append(f"""
%e_{i} = vector.extractelement %transposed[%cst{i}_i32 : i32] : vector<16xi32>
memref.store %e_{i}, %arg1[{store_idx}] : memref<1024xi32>
%store_idx_{i+1} = arith.addi {store_idx}, %cst64 : index""")
    ret.append("""
func.return
}""")
    return '\n'.join(ret)

def swizzleMap(spec: TestSpec, i: int, j: int) -> int:
    size = spec.size
    outI = size * (i // size) + (j % size)
    outJ = size * (j // size) + (i % size)
    return outJ + 64 * outI

def swizzleGoal(spec: TestSpec) -> List[int]:
    unpermuted = [swizzleMap(spec, r, t) for r in range(16) for t in range(64)]
    ret = [unpermuted[4 * (i // 4) + spec.perm[i % 4]]
        for i in range(len(unpermuted))]
    return ret

def hostCode(spec: TestSpec) -> str:
    """Generates the code needed to call a given inWarpTranspose kernel"""
    init = [t + 64 * r for r in range(16) for t in range(64)]
    goal = swizzleGoal(spec)

    ret = f"""
func.func @host_{spec.name}() -> i1 {{
    %init = arith.constant dense<{init}> : tensor<1024xi32>
    %goal = arith.constant dense<{goal}> :  tensor<1024xi32>
    %cst1_i32 = arith.constant 1 : i32
    %cst2_i32 = arith.constant 2 : i32
    %cst_deadbeef_i32 = arith.constant 0xdeadbeef : i32

    %init_mem = bufferization.to_memref %init : memref<1024xi32>
    %goal_mem = bufferization.to_memref %goal : memref<1024xi32>

    %arg = memref.alloc() : memref<1024xi32>
    %res = memref.alloc() : memref<1024xi32>

    memref.copy %init_mem, %arg : memref<1024xi32> to memref<1024xi32>
    %arg_gpu = gpu.alloc() : memref<1024xi32>
    gpu.memcpy %arg_gpu, %arg : memref<1024xi32>, memref<1024xi32>

    %res_gpu = gpu.alloc() : memref<1024xi32>
    gpu.memcpy %res_gpu, %res : memref<1024xi32>, memref<1024xi32>

    func.call @{spec.name}_kern(%arg_gpu, %res_gpu) : (memref<1024xi32>, memref<1024xi32>) -> ()

    gpu.memcpy %res, %res_gpu : memref<1024xi32>, memref<1024xi32>

    %true = arith.constant 1 : i1
    %ret = affine.for %i = 0 to 1024 iter_args(%state = %true) -> (i1) {{
        %goal_e = affine.load %goal_mem[%i] : memref<1024xi32>
        %arg_e = affine.load %res[%i] : memref<1024xi32>
        %current = arith.cmpi eq, %goal_e, %arg_e : i32
        %next = arith.andi %state, %current : i1
        affine.yield %next : i1
    }}
    scf.if %ret {{
        scf.yield
    }} else {{
        %res_no_shape = memref.cast %res : memref<1024xi32> to memref<*xi32>
        func.call @printMemrefI32(%res_no_shape) : (memref<*xi32>) -> ()
    }}
    gpu.dealloc %arg_gpu : memref<1024xi32>
    gpu.dealloc %res_gpu : memref<1024xi32>
    func.return %ret : i1
}}
"""
    return ret

def genTestProgram(specs: List[TestSpec]):
    ret: List[str] = [f"""
module attributes {{gpu.container_module}} {{
    func.func private @printMemrefI32(memref<*xi32>)
"""]
    for spec in specs:
        ret.append(gpuCode(spec))
    for spec in specs:
        ret.append(hostCode(spec))
    ret.append("""
func.func @main() -> i32 {
    %cst0_i32 = arith.constant 0 : i32
    %cst1_i32 = arith.constant 1 : i32
""")
    for spec in specs:
        ret.append(f"%{spec.name} = call @host_{spec.name}() : () -> i1")
    ret.append("%0 = arith.constant 1 : i1")
    for i, spec in enumerate(specs):
        ret.append(f"%{i + 1} = arith.andi %{i}, %{spec.name} : i1")
    ret.append(f"%ret = arith.select %{len(specs)}, %cst0_i32, %cst1_i32 : i32")
    ret.append("""
    return %ret : i32
    }
    }""")
    return "\n".join(ret)

def lowerTestCode(testCode: str) -> str:
    optimizer = "rocmlir-opt"
    if len(sys.argv) >= 2:
        optimizer = sys.argv[1];
    else:
        path = os.getenv("PATH", ".")
        optimizer = shutil.which(optimizer,
            path=f"{path}{os.pathsep}./build/bin{os.pathsep}./bin{os.pathsep}.")
        if optimizer is None:
            raise RuntimeError("Couldn't find rocmlir-opt to transform the test code")

    result = subprocess.run(
        [optimizer, "--convert-linalg-to-affine-loops", "--lower-affine",
        "--arith-bufferize", "--finalizing-bufferize", "--canonicalize",
        "-o", "-", "-"],
        encoding="utf-8", input=testCode, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0 or len(result.stderr) != 0:
        print("Couldn't lower successfully, rocmlir-opt returned:",
            result.returncode, file=sys.stderr)
        print(result.stderr, file=sys.stderr)
    return result.stdout

if __name__ == '__main__':
    testCode = genTestProgram(DEFAULT_SPECS)
    lowered = lowerTestCode(testCode)
    print(testHeader())
    print(lowered)


